{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81825b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.data import get_data_loaders\n",
    "from utils.train_eval import train, train_curriculum\n",
    "from utils.misc import get_features, cluster_features\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8ec806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Either cifar10 or flowers102\n",
    "dataset = \"cifar10\"\n",
    "data_config = {\n",
    "    \"batch_size\": 64,\n",
    "    \"num_workers\": 2,\n",
    "}\n",
    "\n",
    "loaders, num_classes, datasets = get_data_loaders(dataset=dataset,\n",
    "                                                  batch_size=data_config[\"batch_size\"],\n",
    "                                                  num_workers=data_config[\"num_workers\"],\n",
    "                                                  return_dataset=True)\n",
    "\n",
    "train_loader, test_loader = loaders\n",
    "train_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37650cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 782\n",
      "Number of testing batches: 157\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of testing batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a00abed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devin/envs/vision/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/devin/envs/vision/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# which model to use for feature extraction?\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "extractor = vgg16.features\n",
    "\n",
    "# features for all the samples in the train dataloader\n",
    "feats = get_features(extractor, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a8bacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE: If there are too many samples, training KMeans can take a \n",
    "lot of time. To prevent that from happening, you can limit the number\n",
    "of samples being used using this cell (for debugging purposes). \n",
    "E.g., uncomment the last line to only use the first 1000 features.\n",
    "\"\"\"\n",
    "features = feats\n",
    "# features = feats[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3052c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dists = get_pairwise_distance(feats)\n",
    "# print(dists.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69632efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devin/envs/vision/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Number of clusters to split the input samples into using KMeans \n",
    "num_clusters = 5\n",
    "c_labels = cluster_features(features, num_clusters=num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d23ca3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out the data into clusters\n",
    "from collections import defaultdict\n",
    "\n",
    "clustered_data = defaultdict(list)\n",
    "\n",
    "for idx, l in enumerate(c_labels):\n",
    "    clustered_data[l].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab25b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 19180), (3, 13136), (4, 8251), (1, 5887), (0, 3546)]\n"
     ]
    }
   ],
   "source": [
    "# How big are the different clusters?\n",
    "c_sizes = []\n",
    "\n",
    "for l in clustered_data.keys():\n",
    "    c_sizes.append((l, len(clustered_data[l])))\n",
    "\n",
    "# sort by the number of samples in the cluster\n",
    "c_sizes = sorted(c_sizes, key=lambda x: x[1], reverse=True)\n",
    "print(c_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a10547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devin/envs/vision/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/devin/envs/vision/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# the network to be trained\n",
    "model = models.resnet18(pretrained=False)\n",
    "\n",
    "# Change the output of the last FC layer as per the number of classes\n",
    "fc_input = model.fc.in_features\n",
    "model.fc = nn.Linear(fc_input, num_classes)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1175a73d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cluster 2 (38.36% data) done Test Acc: 65.410\n",
      "Training on cluster 3 (26.27% data) done Test Acc: 69.050\n",
      "Training on cluster 4 (16.50% data) done Test Acc: 65.680\n",
      "Training on cluster 1 (11.77% data) done Test Acc: 67.530\n",
      "Training on cluster 0 (7.09% data) done Test Acc: 68.050\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# How many epochs to train for (per cluster)?\n",
    "num_epochs = 1\n",
    "\n",
    "\"\"\"\n",
    "We experimented with two different ways to present data to the model:\n",
    "1. Present clusters in increasing order of cluster size (mode: S2L)\n",
    "2. Present clusters in decreasing order of cluster size (mode: L2S)\n",
    "\"\"\"\n",
    "mode = \"L2S\"\n",
    "\n",
    "params = {\n",
    "    \"model\": model,\n",
    "    \"dataset\": dataset,\n",
    "    \"train_dataset\": train_dataset,\n",
    "    \"test_loader\": test_loader,\n",
    "    \"clustered_data\": clustered_data,\n",
    "    \"c_sizes\": c_sizes,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"criterion\": criterion,\n",
    "    \"mode\": mode,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"data_config\": data_config,\n",
    "    \"device\": device,\n",
    "}\n",
    "\n",
    "train_curriculum(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "462da800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, Batch: 100] Loss: 0.687\n",
      "[Epoch: 1, Batch: 200] Loss: 0.735\n",
      "[Epoch: 1, Batch: 300] Loss: 0.717\n",
      "[Epoch: 1, Batch: 400] Loss: 0.703\n",
      "[Epoch: 1, Batch: 500] Loss: 0.704\n",
      "[Epoch: 1, Batch: 600] Loss: 0.718\n",
      "[Epoch: 1, Batch: 700] Loss: 0.738\n",
      "[Epoch: 2, Batch: 100] Loss: 0.592\n",
      "[Epoch: 2, Batch: 200] Loss: 0.599\n",
      "[Epoch: 2, Batch: 300] Loss: 0.595\n",
      "[Epoch: 2, Batch: 400] Loss: 0.610\n",
      "[Epoch: 2, Batch: 500] Loss: 0.617\n",
      "[Epoch: 2, Batch: 600] Loss: 0.627\n",
      "[Epoch: 2, Batch: 700] Loss: 0.622\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Residual training: Fine-tune the model on the entire dataset for a few epochs\n",
    "\n",
    "num_epochs_res = 2\n",
    "\n",
    "# TensorBoard log directory\n",
    "log_dir = f\"./logs/{dataset}/vgg16_{mode}_{num_epochs}_c{num_clusters}_residual{num_epochs_res}\"\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "config = {\n",
    "    \"opt\": optimizer,\n",
    "    \"crit\": criterion,\n",
    "    \"log_freq_test\": 250,\n",
    "    \"log_freq_tr\": 150, \n",
    "}\n",
    "\n",
    "train(model, train_loader, test_loader, num_epochs_res, config, device, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "228c73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "ckpt_dir = os.path.join(log_dir, \"checkpoints\")\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "torch.save(model, f\"{ckpt_dir}/{num_epochs_res}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
