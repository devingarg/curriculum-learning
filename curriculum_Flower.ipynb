{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81825b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84dcb249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = CustomDataset()\n",
    "# val_dataset = CustomDataset()\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8ec806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations to apply to the CIFAR-10 data\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "download = True\n",
    "# Define the training and test datasets\n",
    "train_dataset = datasets.Flowers102(root='./data', split=\"train\", download=download, transform=data_transforms)\n",
    "test_dataset = datasets.Flowers102(root='./data', split=\"test\", download=download, transform=data_transforms)\n",
    "\n",
    "# Define the dataloaders to load the data in batches during training and testing\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37650cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 16\n",
      "Number of testing batches: 97\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of testing batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "044e6a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asagrawal/private/.env/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/asagrawal/private/.env/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# the network to test\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_classes = 102\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Modify the last fully connected layer\n",
    "fc_input = model.fc.in_features\n",
    "model.fc = nn.Linear(fc_input, num_classes)\n",
    "\n",
    "# print(model)\n",
    "\n",
    "# Step 5: Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4595ecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 11228838\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(torch.numel(p) for p in model.parameters())\n",
    "print(f\"Number of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51effc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./logs/flowers\"  # Set the directory for storing the logs\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3372db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, dataloader):\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cdeee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Loss: 72.77974843978882 Accuracy: 5.294117647058823\n",
      "Epoch 2 : Loss: 85.1068024635315 Accuracy: 1.5686274509803921\n",
      "Epoch 3 : Loss: 72.7414927482605 Accuracy: 3.235294117647059\n",
      "Epoch 4 : Loss: 69.88459157943726 Accuracy: 3.0392156862745097\n",
      "Epoch 5 : Loss: 68.05196237564087 Accuracy: 4.705882352941177\n",
      "Epoch 5 : Test Accuracy: 3.821759635713124\n",
      "Epoch 6 : Loss: 66.67297458648682 Accuracy: 6.372549019607843\n",
      "Epoch 7 : Loss: 64.98480105400085 Accuracy: 6.764705882352941\n",
      "Epoch 8 : Loss: 64.64125323295593 Accuracy: 6.2745098039215685\n",
      "Epoch 9 : Loss: 63.415772676467896 Accuracy: 6.568627450980392\n",
      "Epoch 10 : Loss: 62.55549669265747 Accuracy: 10.588235294117647\n",
      "Epoch 10 : Test Accuracy: 6.309969100666775\n",
      "Epoch 11 : Loss: 59.5215425491333 Accuracy: 11.372549019607844\n",
      "Epoch 12 : Loss: 58.37901329994202 Accuracy: 13.92156862745098\n",
      "Epoch 13 : Loss: 56.818220138549805 Accuracy: 16.07843137254902\n",
      "Epoch 14 : Loss: 54.590399980545044 Accuracy: 19.705882352941178\n",
      "Epoch 15 : Loss: 52.783684968948364 Accuracy: 19.901960784313726\n",
      "Epoch 15 : Test Accuracy: 9.611318913644496\n",
      "Epoch 16 : Loss: 50.76078152656555 Accuracy: 20.49019607843137\n",
      "Epoch 17 : Loss: 50.55721998214722 Accuracy: 19.313725490196077\n",
      "Epoch 18 : Loss: 50.03150534629822 Accuracy: 25.88235294117647\n",
      "Epoch 19 : Loss: 48.31060814857483 Accuracy: 26.176470588235293\n",
      "Epoch 20 : Loss: 45.45053839683533 Accuracy: 27.54901960784314\n",
      "Epoch 20 : Test Accuracy: 10.928606277443487\n",
      "Epoch 21 : Loss: 42.651936054229736 Accuracy: 34.31372549019608\n",
      "Epoch 22 : Loss: 39.42237305641174 Accuracy: 38.627450980392155\n",
      "Epoch 23 : Loss: 35.51127028465271 Accuracy: 41.07843137254902\n",
      "Epoch 24 : Loss: 34.03413140773773 Accuracy: 46.96078431372549\n",
      "Epoch 25 : Loss: 30.298084378242493 Accuracy: 58.13725490196079\n",
      "Epoch 25 : Test Accuracy: 15.742397137745975\n",
      "Epoch 26 : Loss: 24.909806728363037 Accuracy: 59.01960784313726\n",
      "Epoch 27 : Loss: 24.621922612190247 Accuracy: 62.64705882352941\n",
      "Epoch 28 : Loss: 19.388262569904327 Accuracy: 69.50980392156863\n",
      "Epoch 29 : Loss: 17.38639336824417 Accuracy: 79.80392156862744\n",
      "Epoch 30 : Loss: 17.317920923233032 Accuracy: 67.3529411764706\n",
      "Epoch 30 : Test Accuracy: 15.368352577654903\n",
      "Epoch 31 : Loss: 17.562874019145966 Accuracy: 86.66666666666667\n",
      "Epoch 32 : Loss: 9.377797961235046 Accuracy: 86.76470588235294\n",
      "Epoch 33 : Loss: 9.067486464977264 Accuracy: 88.62745098039215\n",
      "Epoch 34 : Loss: 8.684903234243393 Accuracy: 87.94117647058823\n",
      "Epoch 35 : Loss: 7.113534450531006 Accuracy: 91.66666666666667\n",
      "Epoch 35 : Test Accuracy: 16.685639941453896\n",
      "Epoch 36 : Loss: 5.903315916657448 Accuracy: 92.74509803921569\n",
      "Epoch 37 : Loss: 5.449333444237709 Accuracy: 95.49019607843137\n",
      "Epoch 38 : Loss: 4.329348564147949 Accuracy: 95.58823529411765\n",
      "Epoch 39 : Loss: 3.352797858417034 Accuracy: 97.3529411764706\n",
      "Epoch 40 : Loss: 2.595331631600857 Accuracy: 96.66666666666667\n",
      "Epoch 40 : Test Accuracy: 17.726459586924705\n",
      "Epoch 41 : Loss: 1.9746185056865215 Accuracy: 94.70588235294117\n",
      "Epoch 42 : Loss: 3.0754254683852196 Accuracy: 95.98039215686275\n",
      "Epoch 43 : Loss: 2.9063154608011246 Accuracy: 95.88235294117646\n",
      "Epoch 44 : Loss: 3.2934023588895798 Accuracy: 96.86274509803921\n",
      "Epoch 45 : Loss: 2.942989304661751 Accuracy: 95.49019607843137\n",
      "Epoch 45 : Test Accuracy: 17.33615221987315\n",
      "Epoch 46 : Loss: 2.1363228745758533 Accuracy: 99.31372549019608\n",
      "Epoch 47 : Loss: 1.2937123328447342 Accuracy: 98.62745098039215\n",
      "Epoch 48 : Loss: 1.8297833539545536 Accuracy: 97.05882352941177\n",
      "Epoch 49 : Loss: 2.4825307726860046 Accuracy: 97.54901960784314\n",
      "Epoch 50 : Loss: 1.6273079868406057 Accuracy: 98.23529411764706\n",
      "Epoch 50 : Test Accuracy: 16.29533257440234\n",
      "Epoch 51 : Loss: 1.5752774868160486 Accuracy: 97.74509803921569\n",
      "Epoch 52 : Loss: 1.1107108616270125 Accuracy: 99.31372549019608\n",
      "Epoch 53 : Loss: 0.4975867224857211 Accuracy: 99.6078431372549\n",
      "Epoch 54 : Loss: 0.44483071961440146 Accuracy: 98.92156862745098\n",
      "Epoch 55 : Loss: 0.9325274566654116 Accuracy: 99.11764705882354\n",
      "Epoch 55 : Test Accuracy: 17.856562042608555\n",
      "Epoch 56 : Loss: 1.1746459517162293 Accuracy: 96.96078431372548\n",
      "Epoch 57 : Loss: 0.9041669014841318 Accuracy: 99.70588235294117\n",
      "Epoch 58 : Loss: 0.4702877323143184 Accuracy: 99.2156862745098\n",
      "Epoch 59 : Loss: 0.6382192994933575 Accuracy: 99.01960784313725\n",
      "Epoch 60 : Loss: 0.5627997806295753 Accuracy: 99.31372549019608\n",
      "Epoch 60 : Test Accuracy: 18.946170108960807\n",
      "Epoch 61 : Loss: 1.308082233183086 Accuracy: 99.01960784313725\n",
      "Epoch 62 : Loss: 0.8846929525025189 Accuracy: 98.33333333333333\n",
      "Epoch 63 : Loss: 1.2034415788948536 Accuracy: 97.6470588235294\n",
      "Epoch 64 : Loss: 3.1755557507276535 Accuracy: 95.09803921568627\n",
      "Epoch 65 : Loss: 2.683049339801073 Accuracy: 99.2156862745098\n",
      "Epoch 65 : Test Accuracy: 16.441697837046675\n",
      "Epoch 66 : Loss: 1.3851012997329235 Accuracy: 98.82352941176471\n",
      "Epoch 67 : Loss: 1.9775935197249055 Accuracy: 97.45098039215686\n",
      "Epoch 68 : Loss: 2.6554341074079275 Accuracy: 99.01960784313725\n",
      "Epoch 69 : Loss: 2.585873099975288 Accuracy: 97.15686274509804\n",
      "Epoch 70 : Loss: 2.842121046036482 Accuracy: 98.82352941176471\n",
      "Epoch 70 : Test Accuracy: 15.156936087168646\n",
      "Epoch 71 : Loss: 1.4582302533090115 Accuracy: 99.70588235294117\n",
      "Epoch 72 : Loss: 0.4842763957567513 Accuracy: 100.0\n",
      "Epoch 73 : Loss: 0.16132920107338578 Accuracy: 100.0\n",
      "Epoch 74 : Loss: 0.11370778694981709 Accuracy: 99.50980392156863\n",
      "Epoch 75 : Loss: 0.2796791305881925 Accuracy: 100.0\n",
      "Epoch 75 : Test Accuracy: 18.230606602699627\n",
      "Epoch 76 : Loss: 0.24497526895720512 Accuracy: 100.0\n",
      "Epoch 77 : Loss: 0.10625924484338611 Accuracy: 100.0\n",
      "Epoch 78 : Loss: 0.024298309668665752 Accuracy: 100.0\n",
      "Epoch 79 : Loss: 0.007077799011312891 Accuracy: 100.0\n",
      "Epoch 80 : Loss: 0.0037994622471160255 Accuracy: 100.0\n",
      "Epoch 80 : Test Accuracy: 18.653439583672142\n",
      "Epoch 81 : Loss: 0.002874432502721902 Accuracy: 100.0\n",
      "Epoch 82 : Loss: 0.002415563412796473 Accuracy: 100.0\n",
      "Epoch 83 : Loss: 0.002100940044329036 Accuracy: 100.0\n",
      "Epoch 84 : Loss: 0.001864771831606049 Accuracy: 100.0\n",
      "Epoch 85 : Loss: 0.0016867442936927546 Accuracy: 100.0\n",
      "Epoch 85 : Test Accuracy: 18.73475361847455\n",
      "Epoch 86 : Loss: 0.0015321694772865158 Accuracy: 100.0\n",
      "Epoch 87 : Loss: 0.0014055286228540353 Accuracy: 100.0\n",
      "Epoch 88 : Loss: 0.0013083846279187128 Accuracy: 100.0\n",
      "Epoch 89 : Loss: 0.0012093781842850149 Accuracy: 100.0\n",
      "Epoch 90 : Loss: 0.0011298246499791276 Accuracy: 100.0\n",
      "Epoch 90 : Test Accuracy: 18.62091396975118\n",
      "Epoch 91 : Loss: 0.0010606915348034818 Accuracy: 100.0\n",
      "Epoch 92 : Loss: 0.0009985710257751634 Accuracy: 100.0\n",
      "Epoch 93 : Loss: 0.0009452375070395647 Accuracy: 100.0\n",
      "Epoch 94 : Loss: 0.0008919360789150232 Accuracy: 100.0\n",
      "Epoch 95 : Loss: 0.0008460751705570146 Accuracy: 100.0\n",
      "Epoch 95 : Test Accuracy: 18.669702390632622\n",
      "Epoch 96 : Loss: 0.00080247982077708 Accuracy: 100.0\n",
      "Epoch 97 : Loss: 0.0007661534691578709 Accuracy: 100.0\n",
      "Epoch 98 : Loss: 0.0007291391775652301 Accuracy: 100.0\n",
      "Epoch 99 : Loss: 0.0006966700602788478 Accuracy: 100.0\n",
      "Epoch 100 : Loss: 0.0006689995407214155 Accuracy: 100.0\n",
      "Epoch 100 : Test Accuracy: 18.63717677671166\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "log_train_every = 1\n",
    "log_test_every = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "#         if (i+1) % 100 == 0:\n",
    "#             print(f\"[Epoch: {epoch + 1}, Batch: {i + 1}] Loss: {running_loss/100:.3f}\")\n",
    "#             running_loss = 0.0\n",
    "        \n",
    "    # compute training & testing accuracy every couple of iterations        \n",
    "    if (epoch+1) % log_train_every == 0:\n",
    "        train_accuracy = model_eval(model, train_loader)\n",
    "\n",
    "        # Log the loss\n",
    "        #writer.add_scalar('Loss/train', loss.cpu().item(), epoch * len(train_loader) + i)\n",
    "\n",
    "        # Log the training accuracy\n",
    "        #writer.add_scalar('Accuracy/train', train_accuracy, epoch * len(train_loader) + i)\n",
    "        print(f\"Epoch {epoch+1} : Loss: {running_loss} Accuracy: {train_accuracy}\")\n",
    "        \n",
    "    if (epoch+1) % log_test_every == 0:\n",
    "        test_accuracy = model_eval(model, test_loader)\n",
    "\n",
    "        # Log the test accuracy\n",
    "        #writer.add_scalar('Accuracy/test', test_accuracy, epoch * len(train_loader) + i)\n",
    "        print(f\"Epoch {epoch+1} : Test Accuracy: {test_accuracy}\")\n",
    "        \n",
    "writer.close()\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb728430",
   "metadata": {},
   "source": [
    "## Curriculum Learning experiment 1\n",
    "\n",
    "So.. The curriculum for the following training procedure is that we increase the number of classes progressively in the dataset. All original labels are shited by 1. So, label 0 becomes 1, 1 becomes 2.. and so on. \n",
    "We first start with 2 classes 0 and 1 where 0 represents rest of classes and 1 represents the class that was originally 0. Then we work with 3 classes after 2 epochs: 0(rest of the classes), 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d7aada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, classes, num_classes, train=True, total_classes=102):\n",
    "        self.dataset = dataset\n",
    "        self.classes = classes\n",
    "        self.num_classes = num_classes\n",
    "        self.train = train\n",
    "        self.total_classes = total_classes\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.dataset[index]\n",
    "        if not self.train:\n",
    "            return image, (label+1)%self.total_classes# we would reserve 0 for non-existing classes\n",
    "        \n",
    "        if label in self.classes[:self.num_classes]:\n",
    "            return image, (label+1)%self.total_classes\n",
    "        else:\n",
    "            return torch.zeros_like(image), 0# IMPORTANT CHOICE MADE HERE \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "616bc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Reset the model\n",
    "# the network to test\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_classes = 102\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Modify the last fully connected layer\n",
    "fc_input = model.fc.in_features\n",
    "model.fc = nn.Linear(fc_input, num_classes)\n",
    "\n",
    "# print(model)\n",
    "\n",
    "# Step 5: Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08f3a8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Loss: 22.965038020629436 Accuracy: 99.01960784313725\n",
      "Epoch 2 : Loss: 5.857938896864653 Accuracy: 97.05882352941177\n",
      "Epoch 3 : Loss: 2.3122470453338337 Accuracy: 95.09803921568627\n",
      "Epoch 4 : Loss: 3.811110280454159 Accuracy: 93.13725490196079\n",
      "Epoch 5 : Loss: 4.857914738357067 Accuracy: 91.17647058823529\n",
      "Epoch 5 : Test Accuracy: 0.6505122784192552\n",
      "Epoch 6 : Loss: 5.837317258119583 Accuracy: 89.2156862745098\n",
      "Epoch 7 : Loss: 6.8658279702067375 Accuracy: 87.54901960784314\n",
      "Epoch 8 : Loss: 7.7436376214027405 Accuracy: 85.88235294117646\n",
      "Epoch 9 : Loss: 8.885936677455902 Accuracy: 84.41176470588235\n",
      "Epoch 10 : Loss: 9.961875259876251 Accuracy: 82.54901960784314\n",
      "Epoch 10 : Test Accuracy: 1.1058708733127338\n",
      "Epoch 11 : Loss: 10.95996430516243 Accuracy: 80.88235294117646\n",
      "Epoch 12 : Loss: 11.934397637844086 Accuracy: 79.31372549019608\n",
      "Epoch 13 : Loss: 13.16304349899292 Accuracy: 76.96078431372548\n",
      "Epoch 14 : Loss: 14.17261090874672 Accuracy: 75.7843137254902\n",
      "Epoch 15 : Loss: 15.446325480937958 Accuracy: 73.23529411764706\n",
      "Epoch 15 : Test Accuracy: 1.9840624491787282\n",
      "Epoch 16 : Loss: 20.024007976055145 Accuracy: 71.76470588235294\n",
      "Epoch 17 : Loss: 17.711951673030853 Accuracy: 70.49019607843137\n",
      "Epoch 18 : Loss: 18.339542508125305 Accuracy: 68.82352941176471\n",
      "Epoch 19 : Loss: 19.183680951595306 Accuracy: 68.82352941176471\n",
      "Epoch 20 : Loss: 20.050322830677032 Accuracy: 66.76470588235294\n",
      "Epoch 20 : Test Accuracy: 3.2688241990567573\n",
      "Epoch 21 : Loss: 23.343114614486694 Accuracy: 63.333333333333336\n",
      "Epoch 22 : Loss: 24.59614872932434 Accuracy: 62.94117647058823\n",
      "Epoch 23 : Loss: 25.805948615074158 Accuracy: 61.1764705882353\n",
      "Epoch 24 : Loss: 25.88780128955841 Accuracy: 60.68627450980392\n",
      "Epoch 25 : Loss: 25.88806462287903 Accuracy: 60.88235294117647\n",
      "Epoch 25 : Test Accuracy: 5.903398926654741\n",
      "Epoch 26 : Loss: 26.437079668045044 Accuracy: 60.490196078431374\n",
      "Epoch 27 : Loss: 27.320201873779297 Accuracy: 60.490196078431374\n",
      "Epoch 28 : Loss: 28.26498055458069 Accuracy: 55.98039215686274\n",
      "Epoch 29 : Loss: 27.727102398872375 Accuracy: 55.78431372549019\n",
      "Epoch 30 : Loss: 27.680400371551514 Accuracy: 55.19607843137255\n",
      "Epoch 30 : Test Accuracy: 7.204423483493251\n",
      "Epoch 31 : Loss: 27.830376148223877 Accuracy: 58.431372549019606\n",
      "Epoch 32 : Loss: 27.19388723373413 Accuracy: 60.19607843137255\n",
      "Epoch 33 : Loss: 27.983856678009033 Accuracy: 57.94117647058823\n",
      "Epoch 34 : Loss: 26.63519597053528 Accuracy: 56.86274509803921\n",
      "Epoch 35 : Loss: 26.03370237350464 Accuracy: 60.09803921568628\n",
      "Epoch 35 : Test Accuracy: 13.189136444950398\n",
      "Epoch 36 : Loss: 27.871798753738403 Accuracy: 62.254901960784316\n",
      "Epoch 55 : Test Accuracy: 20.344771507562204\n",
      "Epoch 56 : Loss: 4.176328241825104 Accuracy: 95.98039215686275\n",
      "Epoch 57 : Loss: 2.9711302891373634 Accuracy: 96.76470588235294\n",
      "Epoch 58 : Loss: 2.503211982548237 Accuracy: 96.37254901960785\n",
      "Epoch 59 : Loss: 3.831409953534603 Accuracy: 97.84313725490196\n",
      "Epoch 60 : Loss: 2.3203906416893005 Accuracy: 98.62745098039215\n",
      "Epoch 60 : Test Accuracy: 21.889738168807938\n",
      "Epoch 61 : Loss: 1.156681139022112 Accuracy: 99.31372549019608\n",
      "Epoch 62 : Loss: 0.4518795879557729 Accuracy: 99.6078431372549\n",
      "Epoch 63 : Loss: 1.411826960509643 Accuracy: 97.6470588235294\n",
      "Epoch 64 : Loss: 1.1974529214203358 Accuracy: 99.41176470588235\n",
      "Epoch 65 : Loss: 0.33951329602859914 Accuracy: 99.80392156862744\n",
      "Epoch 65 : Test Accuracy: 22.42641079850382\n",
      "Epoch 66 : Loss: 0.10572377895005047 Accuracy: 100.0\n",
      "Epoch 67 : Loss: 0.042363729095086455 Accuracy: 100.0\n",
      "Epoch 68 : Loss: 0.011992595915216953 Accuracy: 100.0\n",
      "Epoch 69 : Loss: 0.006911223492352292 Accuracy: 100.0\n",
      "Epoch 70 : Loss: 0.005584447528235614 Accuracy: 100.0\n",
      "Epoch 70 : Test Accuracy: 22.86550658643682\n",
      "Epoch 71 : Loss: 0.004752855049446225 Accuracy: 100.0\n",
      "Epoch 72 : Loss: 0.004157843315624632 Accuracy: 100.0\n",
      "Epoch 73 : Loss: 0.003707369185576681 Accuracy: 100.0\n",
      "Epoch 74 : Loss: 0.0033740568105713464 Accuracy: 100.0\n",
      "Epoch 75 : Loss: 0.003101336107647512 Accuracy: 100.0\n",
      "Epoch 75 : Test Accuracy: 22.86550658643682\n",
      "Epoch 76 : Loss: 0.0028599883953575045 Accuracy: 100.0\n",
      "Epoch 77 : Loss: 0.0026460465596755967 Accuracy: 100.0\n",
      "Epoch 78 : Loss: 0.0024689794590813108 Accuracy: 100.0\n",
      "Epoch 79 : Loss: 0.002317146794666769 Accuracy: 100.0\n",
      "Epoch 80 : Loss: 0.0021773376429337077 Accuracy: 100.0\n",
      "Epoch 80 : Test Accuracy: 22.97934623516019\n",
      "Epoch 81 : Loss: 0.002054759272141382 Accuracy: 100.0\n",
      "Epoch 82 : Loss: 0.0019385791165404953 Accuracy: 100.0\n",
      "Epoch 83 : Loss: 0.0018411312885291409 Accuracy: 100.0\n",
      "Epoch 84 : Loss: 0.0017395776085322723 Accuracy: 100.0\n",
      "Epoch 85 : Loss: 0.0016634777930448763 Accuracy: 100.0\n",
      "Epoch 85 : Test Accuracy: 23.076923076923077\n",
      "Epoch 86 : Loss: 0.0015786350013513584 Accuracy: 100.0\n",
      "Epoch 87 : Loss: 0.0015064037834235933 Accuracy: 100.0\n",
      "Epoch 88 : Loss: 0.0014437509889830835 Accuracy: 100.0\n",
      "Epoch 89 : Loss: 0.0013834469100402202 Accuracy: 100.0\n",
      "Epoch 90 : Loss: 0.001324387365457369 Accuracy: 100.0\n",
      "Epoch 90 : Test Accuracy: 23.044397463002113\n",
      "Epoch 91 : Loss: 0.0012698516438831575 Accuracy: 100.0\n",
      "Epoch 92 : Loss: 0.00121823621520889 Accuracy: 100.0\n",
      "Epoch 93 : Loss: 0.0011744447983801365 Accuracy: 100.0\n",
      "Epoch 94 : Loss: 0.0011332907306496054 Accuracy: 100.0\n",
      "Epoch 95 : Loss: 0.0010904785776801873 Accuracy: 100.0\n",
      "Epoch 95 : Test Accuracy: 23.060660269962597\n",
      "Epoch 96 : Loss: 0.001055182237905683 Accuracy: 100.0\n",
      "Epoch 97 : Loss: 0.0010144066509383265 Accuracy: 100.0\n",
      "Epoch 98 : Loss: 0.0009825225060922094 Accuracy: 100.0\n",
      "Epoch 99 : Loss: 0.0009484314159635687 Accuracy: 100.0\n",
      "Epoch 100 : Loss: 0.000919965015782509 Accuracy: 100.0\n",
      "Epoch 100 : Test Accuracy: 23.028134656041633\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "curriculum_epochs = 5\n",
    "increment_step = 2\n",
    "nclass = increment_step\n",
    "\n",
    "\n",
    "log_train_every = 1\n",
    "log_test_every = 5\n",
    "\n",
    "test_dataset = SubsetDataset(test_dataset, list(range(num_classes)), num_classes, train=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    subset_classes = list(range(nclass))\n",
    "\n",
    "    # Create the modified dataset\n",
    "    subset_dataset = SubsetDataset(train_dataset, subset_classes, nclass)\n",
    "\n",
    "    # Create the train loader using the modified dataset\n",
    "    train_loader = torch.utils.data.DataLoader(subset_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "#         if (i+1) % 100 == 0:\n",
    "#             print(f\"[Epoch: {epoch + 1}, Batch: {i + 1}] Loss: {running_loss/100:.3f}\")\n",
    "#             running_loss = 0.0\n",
    "        \n",
    "    # compute training & testing accuracy every couple of iterations        \n",
    "    if (epoch+1) % log_train_every == 0:\n",
    "        train_accuracy = model_eval(model, train_loader)\n",
    "\n",
    "        # Log the loss\n",
    "        #writer.add_scalar('Loss/train', loss.cpu().item(), epoch * len(train_loader) + i)\n",
    "\n",
    "        # Log the training accuracy\n",
    "        #writer.add_scalar('Accuracy/train', train_accuracy, epoch * len(train_loader) + i)\n",
    "        print(f\"Epoch {epoch+1} : Loss: {running_loss} Accuracy: {train_accuracy}\")\n",
    "        \n",
    "    if (epoch+1) % log_test_every == 0:\n",
    "        test_accuracy = model_eval(model, test_loader)\n",
    "\n",
    "        # Log the test accuracy\n",
    "        #writer.add_scalar('Accuracy/test', test_accuracy, epoch * len(train_loader) + i)\n",
    "        print(f\"Epoch {epoch+1} : Test Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    nclass += increment_step\n",
    "\n",
    "writer.close()\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379f677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e2ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch 2.0",
   "language": "python",
   "name": "torch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
